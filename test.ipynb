{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "#K.set_image_dim_ordering('tf')\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "\n",
    "###### Tensorflow GPU ########\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relative_path = \"C:\\school\\jaar3\\semester1\\MLOps\\eindopracht_mlops\\Docker\\\\fastapi\\\\model\\\\\"\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "# Read and preprocess images\n",
    "\n",
    "image_size = 48\n",
    "nr_train_images = 1000\n",
    "nr_test_images = 1000\n",
    "angry_images = []\n",
    "happy_images = []\n",
    "sad_images = []\n",
    "\n",
    "# read angry images\n",
    "path = './data/train/angry/'\n",
    "valid_images = [\".jpg\", \".gif\", \".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_train_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path, f))\n",
    "    im = transform.resize(im, (image_size, image_size),\n",
    "                          mode='constant', anti_aliasing=True)\n",
    "    angry_images.append(im)\n",
    "\n",
    "# read happy images\n",
    "\n",
    "path = './data/train/happy/'\n",
    "valid_images = [\".jpg\", \".gif\", \".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_test_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path, f))\n",
    "    im = transform.resize(im, (image_size, image_size),\n",
    "                          mode='constant', anti_aliasing=True)\n",
    "    happy_images.append(im)\n",
    "\n",
    "\n",
    "# read sad images\n",
    "path = './data/train/sad/'\n",
    "valid_images = [\".jpg\", \".gif\", \".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_train_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path, f))\n",
    "    im = transform.resize(im, (image_size, image_size),\n",
    "                          mode='constant', anti_aliasing=True)\n",
    "    sad_images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of each image with the corrosponding class\n",
    "angry = []\n",
    "happy = []\n",
    "sad = []\n",
    "for i in range(len(angry_images)):\n",
    "    angry.append([angry_images[i], 0])\n",
    "\n",
    "for i in range(len(happy_images)):\n",
    "    happy.append([happy_images[i], 1])\n",
    "\n",
    "for i in range(len(sad_images)):\n",
    "    sad.append([sad_images[i], 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the images and labels\n",
    "data = angry + happy + sad\n",
    "\n",
    "# shuffle the data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test set\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(len(data)):\n",
    "    if i < 2000:\n",
    "        X_train.append(data[i][0])\n",
    "        y_train.append(data[i][1])\n",
    "    else:\n",
    "        X_test.append(data[i][0])\n",
    "        y_test.append(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into tensorflow format with grayscale\n",
    "X_train = X_train.reshape(-1, 48, 48, 1)\n",
    "X_test = X_test.reshape(-1, 48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer class labels to one-hot encoded format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2424839735031128\n",
      "Test accuracy: 0.3240000009536743\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
